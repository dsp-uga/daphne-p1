{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m76b3YqlkBP"
      },
      "source": [
        "# import pyspark\r\n",
        "from pyspark import SparkContext\r\n",
        "from pyspark import SparkConf\r\n",
        "from pyspark.sql import SQLContext\r\n",
        "\r\n",
        "# read text files into Spark dataframes\r\n",
        "df_small_X = spark.read.load(\"project1_files_X_small_train.txt\",\r\n",
        "                 format=\"csv\", sep=\" \", inferSchema=\"true\", header=\"false\").toDF(\"X\")\r\n",
        "df_X_train = spark.read.load(\"project1_files_X_train.txt\",\r\n",
        "                 format=\"csv\", sep=\" \", inferSchema=\"true\", header=\"false\").toDF(\"X\")\r\n",
        "df_small_Y = spark.read.load(\"project1_files_y_small_train.txt\",\r\n",
        "                 format=\"csv\", sep=\" \", inferSchema=\"true\", header=\"false\").toDF(\"Y\")\r\n",
        "df_y_train = spark.read.load(\"project1_files_y_train.txt\",\r\n",
        "                 format=\"csv\", sep=\" \", inferSchema=\"true\", header=\"false\").toDF(\"Y\")\r\n",
        "# combine X and Y into one dataframe\r\n",
        "df_small = df_small_X.join(df_small_Y)\r\n",
        "df_train = df_X_train.join(df_y_train)\r\n",
        "df_small.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmEYUZdJln4G"
      },
      "source": [
        "# create Spark context with Spark configuration\r\n",
        "conf = SparkConf().setAppName(\"read text file\")\r\n",
        "sc = SparkContext.getOrCreate(conf=conf)\r\n",
        "\r\n",
        "# using hashes to locate the .asm file\r\n",
        "path = 'hdfs://data/asm'\r\n",
        "def ReadAsm(hash):\r\n",
        "  asm_file = sc.textFile(os.path.join(path, ''.join([hash,'.asm']))) \r\n",
        "  return asm_file\r\n",
        "\r\n",
        "def ReadBytes(hash):\r\n",
        "  bytes_file = sc.textFile(os.path.join(path, ''.join([hash,'.bytes'])))\r\n",
        "  return bytes_file"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}